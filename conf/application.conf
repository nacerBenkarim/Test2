# This is the main configuration file for the application.
# ~~~~~

# Secret key
# ~~~~~
# The secret key is used to secure cryptographics functions.
# If you deploy your application to several instances be sure to use the same key!
application {
  name = "xingCodingChallenge"
  version = "0.1"
  secret = "%APPLICATION_SECRET%" # The secret key is used to secure cryptographics functions.
  # If you deploy you application to several instance be sure to use the same key!
  # The application languages
  langs = "en"
}
# Global object class
# ~~~~~
# Define the Global object class for this application.
# Default to Global in the root package.
application.global=Global

# Router
# ~~~~~
# Define the Router object to use for this application.
# This router will be looked up first when the application is starting up,
# so make sure this is the entry point.
# Furthermore, it's assumed your route file is named properly.
# So for an application router like `my.application.Router`,
# you may need to define a router file `conf/my.application.routes`.
# Default to Routes in the root package (and conf/routes)
# application.router=my.application.Routes

# Evolutions
# ~~~~~
# You can disable evolutions if needed
# evolutionplugin=disabled

# Logger
# ~~~~~
# You can also configure logback (http://logback.qos.ch/),
# by providing an application-logger.xml file in the conf directory.

logger {
  # Root logger
  root = ERROR

  # Logger used by the framework:
  play=INFO

  # Logger provided to your application:
  application=DEBUG

}

app{
  # Database configuration
  database{
    driver = "com.mysql.jdbc.Driver"
    # database url which contains the database name (i.e : database name is 'xing')
    url = "jdbc:mysql://127.0.0.1/xing"
    # database username
    username ="root"
    # database password
    password = ""
  }
  # Spark and JdbcRDD configuration
  spark{
    # maximum result to return
    maxResult = 100
    # the minimum value of the first placeholder
    lowBound = 1
    # the maximum value of the first placeholder
    # The lower and upper bounds are inclusive.
    # If query do not contain any ? placeholder, lowerBound and upperBound can be set to any value.
    upperBound = 100
    # Number of partition will be used by spark for the data.
    # Given a lowerBound of 1, an upperBound of 20, and a numPartitions of 2,
    # the query would be executed twice, once with (1, 10) and once with (11, 20)
    # If query do not contain any ? placeholder, numPartitions must be set to exactly 1.
    numberPartitions = 1

    # memory space to use by spark to run a query(i.e: 1GB)
    executorMemory = "1g"
    # in second
    timeout = 5
    # Allow more than one SparkContext to  run in this JVM
    allowMultipleContexts = true
    # This application will use spark locally.
    address = "local"
    # Number of cores will be use by spark.
    numberCores = 2
  }
}